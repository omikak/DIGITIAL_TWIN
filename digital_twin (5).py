# -*- coding: utf-8 -*-
"""digital twin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojJh7HA7OvhiSiRoW2x2nSkfTm_hnMDV
"""

!pip install fastapi uvicorn streamlit requests scikit-learn numpy pandas plotly pyngrok -q

from google.colab import drive
import os
import shutil

# Mount Drive
drive.mount('/content/drive', force_remount=True)

# Copy dataset to Colab
shutil.copy(
    '/content/drive/MyDrive/CU_Thermal_Twin/thermal_qa_dataset.json',
    '/content/'
)
import os

# Ensure the '/content/' directory exists
if not os.path.exists('/content'):
    os.makedirs('/content')

# Verify
import json
with open('/content/thermal_qa_dataset.json') as f:
    qa_data = json.load(f)

print(f"âœ… Loaded {len(qa_data)} Q&A pairs")
print("âœ… Dataset ready in /content/")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile /content/app_backend.py
# 
# import json
# import logging
# import os
# from pathlib import Path
# from functools import lru_cache
# from typing import List, Dict, Any, Union
# 
# import joblib
# import numpy as np
# import uvicorn
# from fastapi import FastAPI, HTTPException, Request
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel, Field
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.feature_extraction.text import TfidfVectorizer
# 
# # --- Configuration & Logging ---
# 
# # Set up logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)
# 
# # Define base directory and paths for data/models
# BASE_DIR = Path(__file__).resolve().parent
# DATA_FILE = BASE_DIR / "thermal_qa_dataset.json"
# VECTORIZER_FILE = BASE_DIR / "vectorizer.joblib"
# HOTSPOT_MODEL_FILE = BASE_DIR / "hotspot_model.joblib"
# PRIORITY_MODEL_FILE = BASE_DIR / "priority_model.joblib"
# 
# # --- Static Campus Data ---
# 
# # This data is static and loaded once.
# zones_data = {
#     "main_parking": {"temp": 44.1, "uv": 9.9, "name": "Main Parking Lot"},
#     "academic_blocka": {"temp": 37.6, "uv": 8.2, "name": "Academic Block A"},
#     "academic_blockb": {"temp": 36.8, "uv": 8.0, "name": "Academic Block B"},
#     "hostel_boys1": {"temp": 35.9, "uv": 7.8, "name": "Boys Hostel Block 1"},
#     "hostel_boys2": {"temp": 36.3, "uv": 7.9, "name": "Boys Hostel Block 2"},
#     "hostel_girls": {"temp": 35.4, "uv": 7.5, "name": "Girls Hostel Complex"},
#     "sports_complex": {"temp": 41.1, "uv": 10.2, "name": "Sports Stadium"},
#     "library": {"temp": 34.0, "uv": 6.2, "name": "Central Library"},
#     "green_quad": {"temp": 30.2, "uv": 7.6, "name": "Green Quad"},
#     "food_court": {"temp": 37.9, "uv": 8.5, "name": "Food Court"},
#     "bus_stop": {"temp": 37.4, "uv": 9.1, "name": "Bus Stop"},
#     "admin_block": {"temp": 35.2, "uv": 7.7, "name": "Admin Block"},
# }
# 
# # --- Pydantic API Models (for clear contracts) ---
# 
# class QueryRequest(BaseModel):
#     query: str = Field(..., example="What is a heat island?")
# 
# class QAResponse(BaseModel):
#     question: str
#     answer: str
#     confidence: float
# 
# class Zone(BaseModel):
#     zone_id: str
#     zone_name: str
#     temperature: float
#     uv_index: float
#     is_hotspot: bool
#     priority: str = Field(..., example="ğŸ”´ HIGH PRIORITY")
# 
# class ZoneResponse(BaseModel):
#     zones: List[Zone]
#     hotspot_count: int
# 
# class ZoneDetail(BaseModel):
#     zone_id: str
#     zone_name: str
#     temperature: float
#     uv_index: float
#     is_hotspot: bool
#     status: str = Field(..., example="ğŸ”´ HIGH RISK")
# 
# class StatisticsResponse(BaseModel):
#     avg_temperature: float
#     max_temperature: float
#     hotspot_zones: int
#     total_zones: int
#     alert: str = Field(..., example="ğŸ”´ HIGH")
# 
# class ErrorResponse(BaseModel):
#     detail: str
# 
# # --- ML Model Training (Run Once) ---
# 
# def train_and_save_models():
#     """
#     Trains the RAG vectorizer and ML models and saves them to disk.
#     This is run once on first startup if models aren't found.
#     """
#     logger.info("No pre-trained models found. Starting training process...")
# 
#     # 1. Load data
#     try:
#         with open(DATA_FILE, 'r') as f:
#             qa_pairs = json.load(f)
#         logger.info(f"âœ… Loaded {len(qa_pairs)} Q&A pairs")
#     except FileNotFoundError:
#         logger.error(f"CRITICAL: {DATA_FILE} not found. Cannot train RAG.")
#         # In a real app, you might want to raise an exception here
#         qa_pairs = [] # Continue without RAG
#     except json.JSONDecodeError:
#         logger.error(f"CRITICAL: Failed to decode {DATA_FILE}. Check JSON format.")
#         qa_pairs = []
# 
#     # 2. Build RAG
#     if qa_pairs:
#         instructions = [qa['instruction'] for qa in qa_pairs]
#         vectorizer = TfidfVectorizer(max_features=100, lowercase=True, stop_words='english')
#         vectorizer.fit(instructions)
#         joblib.dump(vectorizer, VECTORIZER_FILE)
#         logger.info("âœ… RAG vectorizer trained and saved.")
#     else:
#         logger.warning("Skipping RAG training due to empty dataset.")
# 
# 
#     # 3. Train ML
#     zone_ids = list(zones_data.keys())
#     X_train = np.array([[zones_data[z]['temp'], zones_data[z]['uv']] for z in zone_ids])
#     y_hotspot = np.array([1 if zones_data[z]['temp'] > 40 else 0 for z in zone_ids])
#     y_priority = np.array([3 if zones_data[z]['temp'] > 40 else 2 if zones_data[z]['temp'] > 36 else 1 for z in zone_ids])
# 
#     hotspot_model = RandomForestClassifier(n_estimators=10, random_state=42)
#     hotspot_model.fit(X_train, y_hotspot)
#     joblib.dump(hotspot_model, HOTSPOT_MODEL_FILE)
# 
#     priority_model = RandomForestClassifier(n_estimators=10, random_state=42)
#     priority_model.fit(X_train, y_priority)
#     joblib.dump(priority_model, PRIORITY_MODEL_FILE)
# 
#     logger.info("âœ… ML models (Hotspot, Priority) trained and saved.")
# 
# # --- Caching & Business Logic ---
# 
# @lru_cache(maxsize=1)
# def compute_statistics() -> Dict[str, Any]:
#     """
#     Computes global statistics. Cached to avoid re-calculation.
#     """
#     logger.info("Cache miss. Re-computing statistics...")
#     temps = [z['temp'] for z in zones_data.values()]
#     hotspots = sum(1 for z in zones_data.values() if z['temp'] > 40)
#     avg_temp = round(np.mean(temps), 1) if temps else 0.0
#     max_temp = max(temps) if temps else 0.0
# 
#     if hotspots > 3:
#         alert = "ğŸ”´ HIGH"
#     elif hotspots > 0:
#         alert = "ğŸŸ¡ MEDIUM"
#     else:
#         alert = "ğŸŸ¢ LOW"
# 
#     return {
#         "avg_temperature": avg_temp,
#         "max_temperature": max_temp,
#         "hotspot_zones": hotspots,
#         "total_zones": len(zones_data),
#         "alert": alert
#     }
# 
# def get_priority_recommendation(priority_val: int) -> str:
#     """Helper to convert priority number to readable string."""
#     if priority_val == 3:
#         return "ğŸ”´ HIGH PRIORITY"
#     if priority_val == 2:
#         return "ğŸŸ¡ MEDIUM"
#     return "ğŸŸ¢ LOW"
# 
# # --- FastAPI App Initialization ---
# 
# app = FastAPI(
#     title="CU Thermal Digital Twin API",
#     description="An API for monitoring thermal hotspots and providing Q&A for the CU campus.",
#     version="1.0.0",
#     contact={
#         "name": "Hackathon Team",
#         "url": "http://your-project-link.com",
#     },
# )
# 
# # CORS
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
# 
# # --- Startup Event (Model Loading) ---
# 
# @app.on_event("startup")
# def load_models_on_startup():
#     """
#     On app startup, check if models exist.
#     If not, train and save them.
#     If yes, load them into the app.state.
#     """
#     # Check if all models exist
#     models_exist = (
#         VECTORIZER_FILE.exists() and
#         HOTSPOT_MODEL_FILE.exists() and
#         PRIORITY_MODEL_FILE.exists()
#     )
# 
#     if not models_exist or not DATA_FILE.exists():
#         logger.warning("One or more model/data files missing. Triggering training...")
#         try:
#             train_and_save_models()
#         except Exception as e:
#             logger.critical(f"FATAL: Model training failed: {e}", exc_info=True)
#             # You might want to shut down the app if training is critical
#             # For a hackathon, we can try to proceed
#             app.state.models_loaded = False
#             return
#     else:
#         logger.info("All model files found. Loading from disk...")
# 
#     # Load models into app.state
#     try:
#         app.state.vectorizer = joblib.load(VECTORIZER_FILE)
#         app.state.hotspot_model = joblib.load(HOTSPOT_MODEL_FILE)
#         app.state.priority_model = joblib.load(PRIORITY_MODEL_FILE)
#         # Load Q&A pairs for RAG retrieval
#         with open(DATA_FILE, 'r') as f:
#             app.state.qa_pairs = json.load(f)
#         app.state.instruction_vectors = app.state.vectorizer.transform(
#             [qa['instruction'] for qa in app.state.qa_pairs]
#         )
#         app.state.models_loaded = True
#         logger.info("âœ… All models and RAG data successfully loaded into app state.")
#     except Exception as e:
#         logger.error(f"Error loading models: {e}", exc_info=True)
#         app.state.models_loaded = False
# 
# # --- API Endpoints ---
# 
# @app.get(
#     "/",
#     tags=["General"],
#     summary="Root health check endpoint",
#     description="Check the status of the API."
# )
# def root():
#     return {
#         "status": "online",
#         "models_loaded": getattr(app.state, 'models_loaded', False),
#         "total_zones": len(zones_data)
#     }
# 
# @app.post(
#     "/api/v1/qa-search",
#     tags=["Q&A (RAG)"],
#     summary="Search the thermal Q&A database",
#     description="Uses TF-IDF to find the most relevant answer from the dataset.",
#     response_model=QAResponse,
#     responses={
#         404: {"model": ErrorResponse, "description": "No relevant answer found"},
#         503: {"model": ErrorResponse, "description": "RAG models are not loaded"}
#     }
# )
# def search_qa(request: QueryRequest, fast_api_request: Request):
#     if not getattr(app.state, 'models_loaded', False) or not hasattr(app.state, 'vectorizer'):
#         raise HTTPException(status_code=503, detail="RAG models are not available. Please try again later.")
# 
#     query = request.query.lower()
#     query_vector = app.state.vectorizer.transform([query])
#     similarities = (app.state.instruction_vectors * query_vector.T).toarray().flatten()
#     best_idx = np.argmax(similarities)
#     similarity_score = float(similarities[best_idx])
# 
#     if similarity_score < 0.1: # Confidence threshold
#         raise HTTPException(status_code=404, detail="No relevant answer found for your query.")
# 
#     best_qa = app.state.qa_pairs[best_idx]
#     return QAResponse(
#         question=best_qa['instruction'],
#         answer=best_qa['output'],
#         confidence=min(similarity_score * 100, 100.0)
#     )
# 
# @app.get(
#     "/api/v1/zones",
#     tags=["Zones"],
#     summary="Get all campus zones with predictions",
#     description="Lists all monitored zones with their current data and ML-driven priority.",
#     response_model=ZoneResponse,
#     responses={503: {"model": ErrorResponse, "description": "ML models are not loaded"}}
# )
# def get_all_zones():
#     if not getattr(app.state, 'models_loaded', False):
#         raise HTTPException(status_code=503, detail="ML models are not available. Please try again later.")
# 
#     zones_list = []
#     hotspot_count = 0
#     hotspot_model = app.state.hotspot_model
#     priority_model = app.state.priority_model
# 
#     for zone_id, zone_data in zones_data.items():
#         temp = zone_data['temp']
#         uv = zone_data['uv']
#         features = np.array([[temp, uv]])
# 
#         # Predict using loaded models
#         is_hotspot = bool(hotspot_model.predict(features)[0])
#         priority_val = int(priority_model.predict(features)[0])
#         rec = get_priority_recommendation(priority_val)
# 
#         if is_hotspot:
#             hotspot_count += 1
# 
#         zones_list.append(
#             Zone(
#                 zone_id=zone_id,
#                 zone_name=zone_data['name'],
#                 temperature=temp,
#                 uv_index=uv,
#                 is_hotspot=is_hotspot,
#                 priority=rec
#             )
#         )
# 
#     return ZoneResponse(zones=zones_list, hotspot_count=hotspot_count)
# 
# @app.get(
#     "/api/v1/zone/{zone_id}",
#     tags=["Zones"],
#     summary="Get details for a single zone",
#     description="Provides detailed information and status for a specific zone_id.",
#     response_model=ZoneDetail,
#     responses={
#         404: {"model": ErrorResponse, "description": "Zone not found"},
#         503: {"model": ErrorResponse, "description": "ML models are not loaded"}
#     }
# )
# def get_zone_details(zone_id: str):
#     if not getattr(app.state, 'models_loaded', False):
#         raise HTTPException(status_code=503, detail="ML models are not available. Please try again later.")
# 
#     if zone_id not in zones_data:
#         raise HTTPException(status_code=404, detail="Zone not found")
# 
#     zone_data = zones_data[zone_id]
#     temp = zone_data['temp']
#     uv = zone_data['uv']
#     features = np.array([[temp, uv]])
# 
#     is_hotspot = bool(app.state.hotspot_model.predict(features)[0])
# 
#     return ZoneDetail(
#         zone_id=zone_id,
#         zone_name=zone_data['name'],
#         temperature=temp,
#         uv_index=uv,
#         is_hotspot=is_hotspot,
#         status="ğŸ”´ HIGH RISK" if is_hotspot else "ğŸŸ¢ SAFE"
#     )
# 
# @app.get(
#     "/api/v1/statistics",
#     tags=["General"],
#     summary="Get campus-wide thermal statistics",
#     description="Provides cached, high-level statistics for the entire campus.",
#     response_model=StatisticsResponse
# )
# def get_statistics():
#     # This function call is cached by @lru_cache
#     stats = compute_statistics()
#     return StatisticsResponse(**stats)
# 
# # --- Run Server (for local development) ---
# 
# if __name__ == "__main__":
#     logger.info("Starting Uvicorn server for local development...")
#     # Use reload=True for auto-reloading during development
#     # Pass the app as a string to make reload work correctly
#     uvicorn.run("app_backend:app", host="0.0.0.0", port=8000, reload=True)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile /content/app_frontend.py
# import streamlit as st
# import requests
# import pandas as pd
# import plotly.express as px
# import plotly.graph_objects as go
# from typing import Optional, Dict, Any
# from datetime import datetime
# import os
# 
# # -------------------------------------------------------
# # Dependencies
# # -------------------------------------------------------
# os.system('pip install fastapi uvicorn streamlit requests scikit-learn numpy pandas plotly pyngrok folium streamlit-folium reportlab')
# 
# # -------------------------------------------------------
# # CONFIGURATION
# # -------------------------------------------------------
# st.set_page_config(
#     page_title="CU Thermal Twin - Hackathon Edition",
#     layout="wide",
#     page_icon="ğŸ”¥"
# )
# 
# # Dynamic API URL
# DEFAULT_API_URL = "http://localhost:8000"
# API_URL = st.secrets.get("API_URL", DEFAULT_API_URL)
# 
# # -------------------------------------------------------
# # STYLING
# # -------------------------------------------------------
# st.markdown("""
# <style>
#     body { background: linear-gradient(120deg, #1f1c2c, #928dab); }
#     .main-header { color: #ffffff; font-size: 3rem; font-weight: 900; text-align:center;
#                    background: linear-gradient(90deg,#00c6ff,#0072ff);
#                    -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
#     .metric-card {
#         background: rgba(255,255,255,0.15);
#         backdrop-filter: blur(10px);
#         border-radius: 16px;
#         padding: 20px;
#         box-shadow: 0 4px 30px rgba(0,0,0,0.1);
#         transition: transform 0.2s;
#     }
#     .metric-card:hover { transform: translateY(-5px); }
#     .sidebar .sidebar-content { background: rgba(255,255,255,0.1)!important; }
#     .small-caption { color:#b0b0b0; font-size:0.8rem }
#     hr { border: 0; height: 1px; background: rgba(255,255,255,0.2); }
# </style>
# """, unsafe_allow_html=True)
# 
# # -------------------------------------------------------
# # HELPERS
# # -------------------------------------------------------
# @st.cache_data(ttl=60, show_spinner="Fetching data from backend...")
# def api_get(path: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
#     url = f"{API_URL}{path}"
#     r = requests.get(url, params=params, timeout=10)
#     r.raise_for_status()
#     return r.json()
# 
# @st.cache_data(ttl=60, show_spinner="Processing your request...")
# def api_post(path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
#     url = f"{API_URL}{path}"
#     r = requests.post(url, json=payload, timeout=15)
#     r.raise_for_status()
#     return r.json()
# 
# def parse_lakh(s: Any) -> float:
#     try:
#         return float(str(s).replace("â‚¹", "").replace("L", "").replace(",", "").strip())
#     except Exception:
#         return 0.0
# 
# # -------------------------------------------------------
# # HEADER
# # -------------------------------------------------------
# st.markdown("<div class='main-header'>ğŸ† Chandigarh University Thermal Digital Twin</div>", unsafe_allow_html=True)
# st.markdown("<p style='text-align:center; color:#dcdcdc; font-size:1.2rem;'>Real-time Campus Heat Intelligence & Smart Recommendations</p>", unsafe_allow_html=True)
# st.markdown("<hr>", unsafe_allow_html=True)
# 
# # -------------------------------------------------------
# # SIDEBAR
# # -------------------------------------------------------
# with st.sidebar:
#     st.markdown("## ğŸš€ Navigation")
#     page = st.radio(
#         "Select Feature:",
#         ["ğŸ“Š Dashboard", "â“ Q&A Search", "ğŸŒ¡ï¸ Zone Details", "ğŸ“ˆ Forecast", "ğŸ’° ROI", "ğŸ”¬ Analytics"],
#         index=0
#     )
# 
#     st.markdown("---")
#     st.markdown("### ğŸ“¡ System Status")
#     try:
#         status = api_get("/")
#         st.success("âœ… Backend: Online")
#         st.info(f"ğŸ“Š Q&A Pairs: {status.get('qa_pairs', 0)}")
#         st.info(f"ğŸ—ºï¸ Zones: {status.get('zones', 0)}")
#     except Exception:
#         st.error("âŒ Backend Offline")
# 
# # -------------------------------------------------------
# # PAGE 1: DASHBOARD
# # -------------------------------------------------------
# if page == "ğŸ“Š Dashboard":
#     st.markdown("## ğŸ—ºï¸ **Campus Thermal Overview**")
#     try:
#         zones_resp = api_get("/api/v1/zones")
#         stats = api_get("/api/v1/statistics")
#         zones = zones_resp.get("zones", [])
# 
#         # Metrics
#         col1, col2, col3, col4 = st.columns(4)
#         for col, label, val, delta in [
#             (col1, "Avg Temperature", f"{stats.get('avg_temperature', 0)}Â°C", "Campus Mean"),
#             (col2, "Max Temperature", f"{stats.get('max_temperature', 0)}Â°C", f"+{stats.get('max_temperature', 0)-stats.get('avg_temperature', 0):.1f}Â°C"),
#             (col3, "Hotspot Zones", stats.get("hotspot_zones", 0), "Alert Zones"),
#             (col4, "Alert Level", stats.get("alert_level", "N/A"), "")
#         ]:
#             with col:
#                 st.markdown(f"<div class='metric-card'><h4>{label}</h4><h2>{val}</h2><p class='small-caption'>{delta}</p></div>", unsafe_allow_html=True)
# 
#         st.markdown("---")
#         tabs = st.tabs(["ğŸ“ˆ Charts", "ğŸ“‹ Table"])
# 
#         df_all = pd.DataFrame([
#             {
#                 "Zone": z.get("zone_name", ""),
#                 "Temp (Â°C)": z.get("temperature", 0),
#                 "UV Index": z.get("uv_index", 0),
#                 "Status": "ğŸ”´ Hotspot" if z.get("is_hotspot") else "ğŸŸ¢ Safe",
#                 "Priority": z.get("priority", "N/A")
#             }
#             for z in zones
#         ])
# 
#         with tabs[0]:
#             c1, c2 = st.columns(2)
#             with c1:
#                 if not df_all.empty:
#                     fig1 = px.bar(
#                         df_all, x="Zone", y="Temp (Â°C)", color="Temp (Â°C)",
#                         color_continuous_scale="inferno"
#                     )
#                     fig1.update_layout(title="Temperature by Zone", template="plotly_dark")
#                     st.plotly_chart(fig1, use_container_width=True)
#             with c2:
#                 if not df_all.empty:
#                     fig2 = px.scatter(df_all, x="Zone", y="UV Index", color="UV Index",
#                                       size="UV Index", color_continuous_scale="Viridis")
#                     fig2.update_layout(title="UV Index Levels", template="plotly_dark")
#                     st.plotly_chart(fig2, use_container_width=True)
#         with tabs[1]:
#             st.dataframe(df_all, use_container_width=True)
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
# # -------------------------------------------------------
# # PAGE 2: Q&A
# # -------------------------------------------------------
# elif page == "â“ Q&A Search":
#     st.markdown("## ğŸ¤– Ask Your Question")
#     query = st.text_input("ğŸ” What do you want to know?", placeholder="e.g. Which area is coolest today?")
#     if st.button("Ask"):
#         with st.spinner("Searching knowledge base..."):
#             try:
#                 resp = api_post("/api/v1/qa-search", {"query": query})
#                 st.success("âœ… Found an answer!")
#                 st.write(f"**Q:** {resp.get('question', query)}")
#                 st.write(f"**A:** {resp.get('answer', 'No answer found')}")
#                 st.metric("Confidence", f"{resp.get('confidence', 0)}%")
#             except Exception:
#                 st.error("âŒ Could not retrieve an answer.")
#     st.markdown("---")
#     st.caption("ğŸ’¡ Tip: Try questions like *What are the hotspots?* or *How to reduce temperature in labs?*")
# 
# # -------------------------------------------------------
# # PAGE 3: ZONE DETAILS
# # -------------------------------------------------------
# elif page == "ğŸŒ¡ï¸ Zone Details":
#     st.markdown("## ğŸŒ Zone Insights")
#     try:
#         zones_resp = api_get("/api/v1/zones")
#         zones = zones_resp.get("zones", [])
#         if zones:
#             zone_names = {z.get("zone_name", f"Zone-{i}"): z.get("zone_id") for i, z in enumerate(zones)}
#             selected = st.selectbox("Select Zone:", list(zone_names.keys()))
#             details = api_get(f"/api/v1/zone/{zone_names[selected]}")
#             c1, c2, c3, c4 = st.columns(4)
#             for col, name, val in [
#                 (c1, "Temperature", f"{details.get('temperature', 0)}Â°C"),
#                 (c2, "UV Index", f"{details.get('uv_index', 0)}"),
#                 (c3, "Status", details.get('status', 'N/A')),
#                 (c4, "Priority", details.get('priority', 'N/A'))
#             ]:
#                 with col:
#                     st.metric(name, val)
#             st.markdown("### ğŸ›¡ï¸ Recommendations")
#             recs = [
#                 "ğŸ’§ Stay hydrated regularly",
#                 "ğŸ§´ Use SPF 30+ sunscreen",
#                 "ğŸ•¶ï¸ Avoid direct exposure during peak hours"
#             ]
#             if details.get("is_hotspot"):
#                 recs.insert(0, "ğŸš¨ Hotspot Alert! Take shade immediately.")
#             for r in recs:
#                 st.write(r)
#         else:
#             st.warning("No zone data found.")
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
# # -------------------------------------------------------
# # PAGE 4: FORECAST
# # -------------------------------------------------------
# elif page == "ğŸ“ˆ Forecast":
#     st.markdown("## ğŸ“Š 7-Day Temperature Forecast")
#     try:
#         forecast_resp = api_get("/api/v1/forecast")
#         df = pd.DataFrame(forecast_resp.get("forecast", []))
#         if not df.empty:
#             fig = go.Figure()
#             for col in ["max_temp", "min_temp", "avg_temp"]:
#                 if col in df:
#                     fig.add_trace(go.Scatter(x=df["date"], y=df[col], name=col.title(), mode="lines+markers"))
#             fig.update_layout(template="plotly_dark", title="Temperature Forecast", xaxis_title="Date", yaxis_title="Â°C")
#             st.plotly_chart(fig, use_container_width=True)
#         else:
#             st.info("No forecast data available.")
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
# # -------------------------------------------------------
# # PAGE 5: ROI
# # -------------------------------------------------------
# elif page == "ğŸ’° ROI":
#     st.markdown("## ğŸ’¸ ROI & Cooling Intervention Analysis")
#     interventions = {
#         "shade_trees": "ğŸŒ³ Plant Shade Trees",
#         "cool_roof": "ğŸ  Cool Roof Paint",
#         "mist_cooling": "ğŸ’¨ Mist Cooling System",
#         "green_roof": "ğŸŒ± Green Roof System"
#     }
#     choice = st.selectbox("Choose Strategy:", list(interventions.keys()), format_func=lambda x: interventions[x])
#     try:
#         roi = api_get(f"/api/v1/roi/{choice}")
#         c1, c2, c3, c4 = st.columns(4)
#         for c, title, val in [
#             (c1, "Initial Cost", roi.get("initial_cost", "â‚¹0")),
#             (c2, "Annual Savings", roi.get("annual_savings", "â‚¹0")),
#             (c3, "Payback Period", roi.get("payback_period", "N/A")),
#             (c4, "Cooling Effect", roi.get("cooling_effect", "N/A"))
#         ]:
#             with c:
#                 st.metric(title, val)
#         cost = parse_lakh(roi.get("initial_cost", "0"))
#         savings = parse_lakh(roi.get("annual_savings", "0"))
#         years = list(range(1, 6))
#         cumulative = [savings*y - cost for y in years]
#         fig = px.line(x=years, y=cumulative, title="Cumulative ROI (5 Years)", markers=True)
#         fig.update_layout(template="plotly_dark", xaxis_title="Year", yaxis_title="Net â‚¹ (Lakhs)")
#         st.plotly_chart(fig, use_container_width=True)
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
# # -------------------------------------------------------
# # PAGE 6: ANALYTICS
# # -------------------------------------------------------
# elif page == "ğŸ”¬ Analytics":
#     st.markdown("## ğŸ“Š Smart Insights & Summary")
#     try:
#         data = api_get("/api/v1/insights")
#         col1, col2, col3, col4 = st.columns(4)
#         col1.metric("Temp Variance", f"{data.get('temperature_variance', 0)}Â°CÂ²")
#         col2.metric("Std Dev", f"{data.get('std_deviation', 0)}Â°C")
#         col3.metric("Hotspot %", f"{data.get('hotspot_percentage', 0)}%")
#         col4.metric("Safe Zones %", f"{data.get('safe_zones_percentage', 0)}%")
#         st.markdown("### ğŸ’¡ Recommendations")
#         for rec in data.get("recommendations", []):
#             st.write(f"âœ”ï¸ {rec}")
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
# # -------------------------------------------------------
# # FOOTER
# # -------------------------------------------------------
# st.markdown("<hr>", unsafe_allow_html=True)
# st.markdown("<p style='text-align:center; color:#aaa;'>Made with â¤ï¸ for Chandigarh University | Hackathon 2025</p>", unsafe_allow_html=True)

import subprocess
import threading
import time

print("Starting backend...")

def run_backend():
    subprocess.run(["python", "/content/app_backend.py"])

backend_thread = threading.Thread(target=run_backend, daemon=True)
backend_thread.start()

time.sleep(5)  # Wait for backend to start

print("âœ… Backend started on http://localhost:8000")
print("âœ… Ready for Streamlit!")

!streamlit run /content/app_frontend.py \
  --server.port=8501 \
  --server.address=0.0.0.0 \
  --server.headless=true \
  --logger.level=error

from pyngrok import ngrok
import time

# Get Streamlit URL
time.sleep(3)
public_url = ngrok.connect(8501)
print(f"\nâœ… STREAMLIT URL: {public_url}")
print("\nShare this URL with judges!")

# Add to app_frontend.py under page == "ğŸ“Š Dashboard"

import folium
from streamlit_folium import st_folium

st.markdown("### ğŸ—ºï¸ Campus Thermal Heatmap")

# Create map centered on Chandigarh
m = folium.Map(location=[30.9010, 75.8573], zoom_start=15)

# Add zone markers with colors
zone_coords = {
    "main_parking": [30.9020, 75.8580],
    "academic_blocka": [30.9015, 75.8570],
    "library": [30.9000, 75.8600],
    "green_quad": [30.8990, 75.8585],
    "sports_complex": [30.9030, 75.8550],
}

for zone_id, zone_data in zones.items():
    if zone_id in zone_coords:
        temp = zone_data['temperature']
        color = 'red' if zone_data['is_hotspot'] else 'orange' if temp > 36 else 'green'

        folium.CircleMarker(
            location=zone_coords[zone_id],
            radius=10,
            popup=f"{zone_data['zone_name']}: {temp}Â°C",
            color=color,
            fill=True
        ).add_to(m)

st_folium(m, width=700, height=500)

# Add to app_frontend.py

import pandas as pd
import plotly.graph_objects as go

st.markdown("### ğŸ“ˆ 7-Day Temperature Forecast")

# Generate forecast data
from datetime import datetime, timedelta

dates = [(datetime.now() + timedelta(days=i)).strftime('%b %d') for i in range(7)]
forecast_data = {
    'Date': dates,
    'Max Temp': [42, 43, 41, 40, 39, 38, 37],
    'Min Temp': [28, 29, 28, 27, 26, 25, 24],
    'Avg Temp': [35, 36, 34.5, 33.5, 32.5, 31.5, 30.5]
}

df_forecast = pd.DataFrame(forecast_data)

fig = go.Figure()
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Max Temp'], name='Max'))
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Min Temp'], name='Min'))
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Avg Temp'], name='Average'))

st.plotly_chart(fig, use_container_width=True)

# Add new page to app_frontend.py

elif page == "ğŸ’° ROI Calculator":
    st.markdown("## ğŸ’° Cooling Intervention ROI")

    intervention = st.selectbox(
        "Select Intervention:",
        ["Shade Trees", "Cool Roof Paint", "Mist Cooling", "Green Roof"]
    )

    roi_data = {
        "Shade Trees": {"cost": 2, "savings": 0.25, "payback": 8},
        "Cool Roof Paint": {"cost": 3, "savings": 0.40, "payback": 7.5},
        "Mist Cooling": {"cost": 4, "savings": 0.15, "payback": 26},
        "Green Roof": {"cost": 10, "savings": 0.50, "payback": 20},
    }

    data = roi_data[intervention]

    col1, col2, col3 = st.columns(3)
    col1.metric("Initial Cost", f"â‚¹{data['cost']}L")
    col2.metric("Annual Savings", f"â‚¹{data['savings']}L")
    col3.metric("Payback Period", f"{data['payback']} years")

    # 5-year projection
    years = list(range(1, 6))
    savings = [data['savings'] * y - data['cost'] for y in years]

    fig = px.line(x=years, y=savings, markers=True, title="5-Year ROI Projection")
    st.plotly_chart(fig, use_container_width=True)

# Add new endpoint to app_backend.py

@app.get("/api/v1/insights")
def get_ml_insights():
    """
    Advanced ML insights about campus thermal patterns
    """
    temps = [z['temp'] for z in zones_data.values()]

    # Calculate statistics
    variance = float(np.var(temps))
    std_dev = float(np.std(temps))

    # Trend analysis
    hotspot_zones = [z for z in zones_data.values() if z['temp'] > 40]
    safe_zones = [z for z in zones_data.values() if z['temp'] < 35]

    return {
        "temperature_variance": round(variance, 2),
        "std_deviation": round(std_dev, 2),
        "hotspot_percentage": round(len(hotspot_zones) / len(zones_data) * 100, 1),
        "safe_zones_percentage": round(len(safe_zones) / len(zones_data) * 100, 1),
        "recommendations": [
            f"Prioritize cooling in {len(hotspot_zones)} high-risk zones",
            f"Monitor {len(zones_data) - len(hotspot_zones) - len(safe_zones)} moderate zones",
            f"Maintain {len(safe_zones)} safe zones"
        ]
    }

elif page == "ğŸ“Š Analytics":
    st.markdown("## ğŸ“ˆ Advanced Analytics")

    insights = requests.get(f"{API_URL}/api/v1/insights").json()

    col1, col2, col3 = st.columns(3)
    col1.metric("Temp Variance", f"{insights['temperature_variance']}Â°CÂ²")
    col2.metric("Hotspot %", f"{insights['hotspot_percentage']}%")
    col3.metric("Safe Zones %", f"{insights['safe_zones_percentage']}%")

    st.markdown("### AI Recommendations:")
    for rec in insights['recommendations']:
        st.write(f"ğŸ¤– {rec}")

elif page == "âš–ï¸ Compare Zones":
    st.markdown("## âš–ï¸ Zone Comparison")

    response = requests.get(f"{API_URL}/api/v1/zones").json()
    zones = response['zones']
    zone_names = [z['zone_name'] for z in zones]

    col1, col2 = st.columns(2)

    with col1:
        zone1 = st.selectbox("Zone 1:", zone_names, key="z1")

    with col2:
        zone2 = st.selectbox("Zone 2:", zone_names, key="z2")

    z1_data = next(z for z in zones if z['zone_name'] == zone1)
    z2_data = next(z for z in zones if z['zone_name'] == zone2)

    comparison_df = pd.DataFrame({
        'Metric': ['Temperature', 'UV Index', 'Status'],
        zone1: [f"{z1_data['temperature']}Â°C", z1_data['uv_index'],
                'ğŸ”´ Hotspot' if z1_data['is_hotspot'] else 'ğŸŸ¢ Safe'],
        zone2: [f"{z2_data['temperature']}Â°C", z2_data['uv_index'],
                'ğŸ”´ Hotspot' if z2_data['is_hotspot'] else 'ğŸŸ¢ Safe']
    })

    st.dataframe(comparison_df)

# Add custom CSS for responsiveness
st.markdown("""
<style>
    .metric {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
    }

    .stButton > button {
        width: 100%;
        height: 45px;
        font-size: 16px;
    }

    @media (max-width: 768px) {
        .stMetric {
            min-width: 100%;
        }
    }
</style>
""", unsafe_allow_html=True)
# -*- coding: utf-8 -*-
"""digital twin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ojJh7HA7OvhiSiRoW2x2nSkfTm_hnMDV
"""

!pip install fastapi uvicorn streamlit requests scikit-learn numpy pandas plotly pyngrok -q

from google.colab import drive
import os
import shutil

# Mount Drive
drive.mount('/content/drive', force_remount=True)

# Copy dataset to Colab
shutil.copy(
    '/content/drive/MyDrive/CU_Thermal_Twin/thermal_qa_dataset.json',
    '/content/'
)
import os

# Ensure the '/content/' directory exists
if not os.path.exists('/content'):
    os.makedirs('/content')

# Verify
import json
with open('/content/thermal_qa_dataset.json') as f:
    qa_data = json.load(f)

print(f"âœ… Loaded {len(qa_data)} Q&A pairs")
print("âœ… Dataset ready in /content/")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile /content/app_backend.py
# 
# import json
# import logging
# import os
# from pathlib import Path
# from functools import lru_cache
# from typing import List, Dict, Any, Union
# 
# import joblib
# import numpy as np
# import uvicorn
# from fastapi import FastAPI, HTTPException, Request
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel, Field
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.feature_extraction.text import TfidfVectorizer
# 
# # --- Configuration & Logging ---
# 
# # Set up logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)
# 
# # Define base directory and paths for data/models
# BASE_DIR = Path(__file__).resolve().parent
# DATA_FILE = BASE_DIR / "thermal_qa_dataset.json"
# VECTORIZER_FILE = BASE_DIR / "vectorizer.joblib"
# HOTSPOT_MODEL_FILE = BASE_DIR / "hotspot_model.joblib"
# PRIORITY_MODEL_FILE = BASE_DIR / "priority_model.joblib"
# 
# # --- Static Campus Data ---
# 
# # This data is static and loaded once.
# zones_data = {
#     "main_parking": {"temp": 44.1, "uv": 9.9, "name": "Main Parking Lot"},
#     "academic_blocka": {"temp": 37.6, "uv": 8.2, "name": "Academic Block A"},
#     "academic_blockb": {"temp": 36.8, "uv": 8.0, "name": "Academic Block B"},
#     "hostel_boys1": {"temp": 35.9, "uv": 7.8, "name": "Boys Hostel Block 1"},
#     "hostel_boys2": {"temp": 36.3, "uv": 7.9, "name": "Boys Hostel Block 2"},
#     "hostel_girls": {"temp": 35.4, "uv": 7.5, "name": "Girls Hostel Complex"},
#     "sports_complex": {"temp": 41.1, "uv": 10.2, "name": "Sports Stadium"},
#     "library": {"temp": 34.0, "uv": 6.2, "name": "Central Library"},
#     "green_quad": {"temp": 30.2, "uv": 7.6, "name": "Green Quad"},
#     "food_court": {"temp": 37.9, "uv": 8.5, "name": "Food Court"},
#     "bus_stop": {"temp": 37.4, "uv": 9.1, "name": "Bus Stop"},
#     "admin_block": {"temp": 35.2, "uv": 7.7, "name": "Admin Block"},
# }
# 
# # --- Pydantic API Models (for clear contracts) ---
# 
# class QueryRequest(BaseModel):
#     query: str = Field(..., example="What is a heat island?")
# 
# class QAResponse(BaseModel):
#     question: str
#     answer: str
#     confidence: float
# 
# class Zone(BaseModel):
#     zone_id: str
#     zone_name: str
#     temperature: float
#     uv_index: float
#     is_hotspot: bool
#     priority: str = Field(..., example="ðŸ”´ HIGH PRIORITY")
# 
# class ZoneResponse(BaseModel):
#     zones: List[Zone]
#     hotspot_count: int
# 
# class ZoneDetail(BaseModel):
#     zone_id: str
#     zone_name: str
#     temperature: float
#     uv_index: float
#     is_hotspot: bool
#     status: str = Field(..., example="ðŸ”´ HIGH RISK")
# 
# class StatisticsResponse(BaseModel):
#     avg_temperature: float
#     max_temperature: float
#     hotspot_zones: int
#     total_zones: int
#     alert: str = Field(..., example="ðŸ”´ HIGH")
# 
# class ErrorResponse(BaseModel):
#     detail: str
# 
# # --- ML Model Training (Run Once) ---
# 
# def train_and_save_models():
#     """
#     Trains the RAG vectorizer and ML models and saves them to disk.
#     This is run once on first startup if models aren't found.
#     """
#     logger.info("No pre-trained models found. Starting training process...")
# 
#     # 1. Load data
#     try:
#         with open(DATA_FILE, 'r') as f:
#             qa_pairs = json.load(f)
#         logger.info(f"âœ… Loaded {len(qa_pairs)} Q&A pairs")
#     except FileNotFoundError:
#         logger.error(f"CRITICAL: {DATA_FILE} not found. Cannot train RAG.")
#         # In a real app, you might want to raise an exception here
#         qa_pairs = [] # Continue without RAG
#     except json.JSONDecodeError:
#         logger.error(f"CRITICAL: Failed to decode {DATA_FILE}. Check JSON format.")
#         qa_pairs = []
# 
#     # 2. Build RAG
#     if qa_pairs:
#         instructions = [qa['instruction'] for qa in qa_pairs]
#         vectorizer = TfidfVectorizer(max_features=100, lowercase=True, stop_words='english')
#         vectorizer.fit(instructions)
#         joblib.dump(vectorizer, VECTORIZER_FILE)
#         logger.info("âœ… RAG vectorizer trained and saved.")
#     else:
#         logger.warning("Skipping RAG training due to empty dataset.")
# 
# 
#     # 3. Train ML
#     zone_ids = list(zones_data.keys())
#     X_train = np.array([[zones_data[z]['temp'], zones_data[z]['uv']] for z in zone_ids])
#     y_hotspot = np.array([1 if zones_data[z]['temp'] > 40 else 0 for z in zone_ids])
#     y_priority = np.array([3 if zones_data[z]['temp'] > 40 else 2 if zones_data[z]['temp'] > 36 else 1 for z in zone_ids])
# 
#     hotspot_model = RandomForestClassifier(n_estimators=10, random_state=42)
#     hotspot_model.fit(X_train, y_hotspot)
#     joblib.dump(hotspot_model, HOTSPOT_MODEL_FILE)
# 
#     priority_model = RandomForestClassifier(n_estimators=10, random_state=42)
#     priority_model.fit(X_train, y_priority)
#     joblib.dump(priority_model, PRIORITY_MODEL_FILE)
# 
#     logger.info("âœ… ML models (Hotspot, Priority) trained and saved.")
# 
# # --- Caching & Business Logic ---
# 
# @lru_cache(maxsize=1)
# def compute_statistics() -> Dict[str, Any]:
#     """
#     Computes global statistics. Cached to avoid re-calculation.
#     """
#     logger.info("Cache miss. Re-computing statistics...")
#     temps = [z['temp'] for z in zones_data.values()]
#     hotspots = sum(1 for z in zones_data.values() if z['temp'] > 40)
#     avg_temp = round(np.mean(temps), 1) if temps else 0.0
#     max_temp = max(temps) if temps else 0.0
# 
#     if hotspots > 3:
#         alert = "ðŸ”´ HIGH"
#     elif hotspots > 0:
#         alert = "ðŸŸ¡ MEDIUM"
#     else:
#         alert = "ðŸŸ¢ LOW"
# 
#     return {
#         "avg_temperature": avg_temp,
#         "max_temperature": max_temp,
#         "hotspot_zones": hotspots,
#         "total_zones": len(zones_data),
#         "alert": alert
#     }
# 
# def get_priority_recommendation(priority_val: int) -> str:
#     """Helper to convert priority number to readable string."""
#     if priority_val == 3:
#         return "ðŸ”´ HIGH PRIORITY"
#     if priority_val == 2:
#         return "ðŸŸ¡ MEDIUM"
#     return "ðŸŸ¢ LOW"
# 
# # --- FastAPI App Initialization ---
# 
# app = FastAPI(
#     title="CU Thermal Digital Twin API",
#     description="An API for monitoring thermal hotspots and providing Q&A for the CU campus.",
#     version="1.0.0",
#     contact={
#         "name": "Hackathon Team",
#         "url": "http://your-project-link.com",
#     },
# )
# 
# # CORS
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
# 
# # --- Startup Event (Model Loading) ---
# 
# @app.on_event("startup")
# def load_models_on_startup():
#     """
#     On app startup, check if models exist.
#     If not, train and save them.
#     If yes, load them into the app.state.
#     """
#     # Check if all models exist
#     models_exist = (
#         VECTORIZER_FILE.exists() and
#         HOTSPOT_MODEL_FILE.exists() and
#         PRIORITY_MODEL_FILE.exists()
#     )
# 
#     if not models_exist or not DATA_FILE.exists():
#         logger.warning("One or more model/data files missing. Triggering training...")
#         try:
#             train_and_save_models()
#         except Exception as e:
#             logger.critical(f"FATAL: Model training failed: {e}", exc_info=True)
#             # You might want to shut down the app if training is critical
#             # For a hackathon, we can try to proceed
#             app.state.models_loaded = False
#             return
#     else:
#         logger.info("All model files found. Loading from disk...")
# 
#     # Load models into app.state
#     try:
#         app.state.vectorizer = joblib.load(VECTORIZER_FILE)
#         app.state.hotspot_model = joblib.load(HOTSPOT_MODEL_FILE)
#         app.state.priority_model = joblib.load(PRIORITY_MODEL_FILE)
#         # Load Q&A pairs for RAG retrieval
#         with open(DATA_FILE, 'r') as f:
#             app.state.qa_pairs = json.load(f)
#         app.state.instruction_vectors = app.state.vectorizer.transform(
#             [qa['instruction'] for qa in app.state.qa_pairs]
#         )
#         app.state.models_loaded = True
#         logger.info("âœ… All models and RAG data successfully loaded into app state.")
#     except Exception as e:
#         logger.error(f"Error loading models: {e}", exc_info=True)
#         app.state.models_loaded = False
# 
# # --- API Endpoints ---
# 
# @app.get(
#     "/",
#     tags=["General"],
#     summary="Root health check endpoint",
#     description="Check the status of the API."
# )
# def root():
#     return {
#         "status": "online",
#         "models_loaded": getattr(app.state, 'models_loaded', False),
#         "total_zones": len(zones_data)
#     }
# 
# @app.post(
#     "/api/v1/qa-search",
#     tags=["Q&A (RAG)"],
#     summary="Search the thermal Q&A database",
#     description="Uses TF-IDF to find the most relevant answer from the dataset.",
#     response_model=QAResponse,
#     responses={
#         404: {"model": ErrorResponse, "description": "No relevant answer found"},
#         503: {"model": ErrorResponse, "description": "RAG models are not loaded"}
#     }
# )
# def search_qa(request: QueryRequest, fast_api_request: Request):
#     if not getattr(app.state, 'models_loaded', False) or not hasattr(app.state, 'vectorizer'):
#         raise HTTPException(status_code=503, detail="RAG models are not available. Please try again later.")
# 
#     query = request.query.lower()
#     query_vector = app.state.vectorizer.transform([query])
#     similarities = (app.state.instruction_vectors * query_vector.T).toarray().flatten()
#     best_idx = np.argmax(similarities)
#     similarity_score = float(similarities[best_idx])
# 
#     if similarity_score < 0.1: # Confidence threshold
#         raise HTTPException(status_code=404, detail="No relevant answer found for your query.")
# 
#     best_qa = app.state.qa_pairs[best_idx]
#     return QAResponse(
#         question=best_qa['instruction'],
#         answer=best_qa['output'],
#         confidence=min(similarity_score * 100, 100.0)
#     )
# 
# @app.get(
#     "/api/v1/zones",
#     tags=["Zones"],
#     summary="Get all campus zones with predictions",
#     description="Lists all monitored zones with their current data and ML-driven priority.",
#     response_model=ZoneResponse,
#     responses={503: {"model": ErrorResponse, "description": "ML models are not loaded"}}
# )
# def get_all_zones():
#     if not getattr(app.state, 'models_loaded', False):
#         raise HTTPException(status_code=503, detail="ML models are not available. Please try again later.")
# 
#     zones_list = []
#     hotspot_count = 0
#     hotspot_model = app.state.hotspot_model
#     priority_model = app.state.priority_model
# 
#     for zone_id, zone_data in zones_data.items():
#         temp = zone_data['temp']
#         uv = zone_data['uv']
#         features = np.array([[temp, uv]])
# 
#         # Predict using loaded models
#         is_hotspot = bool(hotspot_model.predict(features)[0])
#         priority_val = int(priority_model.predict(features)[0])
#         rec = get_priority_recommendation(priority_val)
# 
#         if is_hotspot:
#             hotspot_count += 1
# 
#         zones_list.append(
#             Zone(
#                 zone_id=zone_id,
#                 zone_name=zone_data['name'],
#                 temperature=temp,
#                 uv_index=uv,
#                 is_hotspot=is_hotspot,
#                 priority=rec
#             )
#         )
# 
#     return ZoneResponse(zones=zones_list, hotspot_count=hotspot_count)
# 
# @app.get(
#     "/api/v1/zone/{zone_id}",
#     tags=["Zones"],
#     summary="Get details for a single zone",
#     description="Provides detailed information and status for a specific zone_id.",
#     response_model=ZoneDetail,
#     responses={
#         404: {"model": ErrorResponse, "description": "Zone not found"},
#         503: {"model": ErrorResponse, "description": "ML models are not loaded"}
#     }
# )
# def get_zone_details(zone_id: str):
#     if not getattr(app.state, 'models_loaded', False):
#         raise HTTPException(status_code=503, detail="ML models are not available. Please try again later.")
# 
#     if zone_id not in zones_data:
#         raise HTTPException(status_code=404, detail="Zone not found")
# 
#     zone_data = zones_data[zone_id]
#     temp = zone_data['temp']
#     uv = zone_data['uv']
#     features = np.array([[temp, uv]])
# 
#     is_hotspot = bool(app.state.hotspot_model.predict(features)[0])
# 
#     return ZoneDetail(
#         zone_id=zone_id,
#         zone_name=zone_data['name'],
#         temperature=temp,
#         uv_index=uv,
#         is_hotspot=is_hotspot,
#         status="ðŸ”´ HIGH RISK" if is_hotspot else "ðŸŸ¢ SAFE"
#     )
# 
# @app.get(
#     "/api/v1/statistics",
#     tags=["General"],
#     summary="Get campus-wide thermal statistics",
#     description="Provides cached, high-level statistics for the entire campus.",
#     response_model=StatisticsResponse
# )
# def get_statistics():
#     # This function call is cached by @lru_cache
#     stats = compute_statistics()
#     return StatisticsResponse(**stats)
# 
# # --- Run Server (for local development) ---
# 
# if __name__ == "__main__":
#     logger.info("Starting Uvicorn server for local development...")
#     # Use reload=True for auto-reloading during development
#     # Pass the app as a string to make reload work correctly
#     uvicorn.run("app_backend:app", host="0.0.0.0", port=8000, reload=True)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile /content/app_frontend.py
# import streamlit as st
# import requests
# import pandas as pd
# import plotly.express as px
# import plotly.graph_objects as go
# from typing import Optional, Dict, Any
# from datetime import datetime
# import os
# os.system('pip install fastapi uvicorn streamlit requests scikit-learn numpy pandas plotly pyngrok folium streamlit-folium reportlab')
# # ------------------------ Base config ------------------------
# st.set_page_config(
#     page_title="CU Thermal Twin",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )
# 
# # Secrets with safe default (do not hardcode in production)
# DEFAULT_API_URL = "http://localhost:8000"
# API_URL = st.secrets.get("API_URL", DEFAULT_API_URL)
# 
# # ------------------------ Styling ------------------------
# st.markdown("""
# <style>
#     .main-header { color: #FF6B6B; font-size: 2.6rem; font-weight: 800; }
#     .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
#                    padding: 16px; border-radius: 10px; color: white; }
#     .small-caption { color:#6c757d; font-size:0.85rem }
# </style>
# """, unsafe_allow_html=True)
# 
# # ------------------------ Helpers: API + parsing ------------------------
# @st.cache_data(ttl=60, show_spinner="Contacting backend...")
# def api_get(path: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
#     url = f"{API_URL}{path}"
#     r = requests.get(url, params=params, timeout=10)
#     r.raise_for_status()
#     return r.json()
# 
# @st.cache_data(ttl=60, show_spinner="Submitting request...")
# def api_post(path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
#     url = f"{API_URL}{path}"
#     r = requests.post(url, json=payload, timeout=15)
#     r.raise_for_status()
#     return r.json()
# 
# def parse_lakh(s: Any) -> float:
#     try:
#         return float(str(s).replace("â‚¹", "").replace("L", "").replace(",", "").strip())
#     except Exception:
#         return 0.0
# 
# # ------------------------ Header ------------------------
# st.markdown("# ðŸ† Chandigarh University Thermal Digital Twin")
# st.markdown("### Real-time Campus Thermal Analysis & Smart Recommendations")
# 
# # ------------------------ Sidebar ------------------------
# with st.sidebar:
#     st.markdown("## ðŸŽ¯ Navigation")
#     page = st.radio(
#         "Select Feature:",
#         ["ðŸ“Š Dashboard", "â“ Q&A Search", "ðŸŒ¡ï¸ Zone Details", "ðŸ“ˆ Forecast", "ðŸ’° ROI", "ðŸ”¬ Analytics"],
#         index=0
#     )
# 
#     st.markdown("---")
#     st.markdown("### ðŸ“¡ System Status")
#     try:
#         status = api_get("/")
#         st.success("âœ… Backend: Online")
#         st.info(f"ðŸ“Š Q&A Pairs: {status.get('qa_pairs', 0)}")
#         st.info(f"ðŸ—ºï¸ Zones: {status.get('zones', 0)}")
#     except Exception:
#         st.error("âŒ Backend Offline")
# 
# # =========================================================
# # PAGE 1: DASHBOARD
# # =========================================================
# if page == "ðŸ“Š Dashboard":
#     st.markdown("## ðŸ—ºï¸ Campus Thermal Overview")
#     try:
#         zones_resp = api_get("/api/v1/zones")
#         stats = api_get("/api/v1/statistics")
#         zones = zones_resp.get("zones", [])
# 
#         # Metrics
#         col1, col2, col3, col4 = st.columns(4)
#         avg_t = stats.get("avg_temperature", 0)
#         max_t = stats.get("max_temperature", 0)
#         hot_cnt = stats.get("hotspot_zones", 0)
#         alert = stats.get("alert_level", "N/A")
# 
#         with col1:
#             st.metric("Avg Temperature", f"{avg_t}Â°C", delta="Campus avg")
#         with col2:
#             try:
#                 st.metric("Max Temperature", f"{max_t}Â°C", delta=f"+{(max_t-avg_t):.1f}Â°C")
#             except Exception:
#                 st.metric("Max Temperature", f"{max_t}Â°C")
#         with col3:
#             st.metric("Hotspot Zones", hot_cnt, delta_color="inverse")
#         with col4:
#             st.metric("Alert Level", alert)
# 
#         st.markdown("---")
#         tabs = st.tabs(["Charts", "Table"])
# 
#         # DataFrames
#         df_temp = pd.DataFrame([
#             {"Zone": z.get("zone_name", "")[:20],
#              "Temp (Â°C)": z.get("temperature", 0),
#              "Status": "ðŸ”´ Hot" if z.get("is_hotspot") else "ðŸŸ¢ Safe"}
#             for z in zones
#         ])
#         df_uv = pd.DataFrame([
#             {"Zone": z.get("zone_name", "")[:20],
#              "UV": z.get("uv_index", 0)}
#             for z in zones
#         ])
#         df_all = pd.DataFrame([
#             {
#                 "Zone": z.get("zone_name", ""),
#                 "Temp (Â°C)": z.get("temperature", 0),
#                 "UV Index": z.get("uv_index", 0),
#                 "Status": "ðŸ”´ Hotspot" if z.get("is_hotspot") else "ðŸŸ¢ Safe",
#                 "Priority": z.get("priority", "N/A")
#             }
#             for z in zones
#         ])
# 
#         with tabs[0]:
#             c1, c2 = st.columns(2)
#             with c1:
#                 st.markdown("### Temperature Distribution")
#                 if not df_temp.empty:
#                     fig1 = px.bar(
#                         df_temp, x="Zone", y="Temp (Â°C)",
#                         color="Temp (Â°C)", color_continuous_scale="RdYlGn_r"
#                     )
#                     st.plotly_chart(fig1, use_container_width=True)
#                 else:
#                     st.info("No zone data available")
#             with c2:
#                 st.markdown("### UV Index Levels")
#                 if not df_uv.empty:
#                     fig2 = px.scatter(
#                         df_uv, x="Zone", y="UV",
#                         size="UV", color="UV", color_continuous_scale="Reds"
#                     )
#                     st.plotly_chart(fig2, use_container_width=True)
#                 else:
#                     st.info("No UV data available")
# 
#         with tabs[1]:
#             st.markdown("### ðŸ“‹ All Zones Data")
#             st.dataframe(df_all, use_container_width=True)
# 
#     except Exception as e:
#         st.error(f"Error: {e}")
# 
# # =========================================================
# # PAGE 2: Q&A SEARCH
# # =========================================================
# elif page == "â“ Q&A Search":
#     st.markdown("## ðŸ” Ask About Campus Thermal")
# 
#     if "qa_query" not in st.session_state:
#         st.session_state.qa_query = ""
# 
#     query = st.text_input(
#         "Enter your question:",
#         key="qa_query",
#         placeholder="e.g., Which zone is the coolest? What are hotspots? How to cool parking?"
#     )
# 
#     colA, colB = st.columns([3, 1])
#     with colA:
#         ask = st.button("Ask")
#     with colB:
#         clear = st.button("Clear")
# 
#     if clear:
#         st.session_state.qa_query = ""
# 
#     if ask and st.session_state.qa_query.strip():
#         try:
#             response = api_post("/api/v1/qa-search", {"query": st.session_state.qa_query})
#             col1, col2 = st.columns([4, 1])
#             with col1:
#                 st.markdown("### ðŸ“Œ Answer")
#                 st.write(f"Q: {response.get('question', st.session_state.qa_query)}")
#                 st.write(f"A: {response.get('answer', 'No answer found')}")
#             with col2:
#                 conf = response.get("confidence", 0)
#                 try:
#                     st.metric("Match", f"{float(conf):.0f}%")
#                 except Exception:
#                     st.metric("Match", f"{conf}")
#             st.success("âœ… Retrieved from knowledge base")
#         except Exception:
#             st.error("Could not retrieve answer")
# 
#     st.markdown("---")
#     st.markdown("### ðŸ’¡ Sample Questions")
#     samples = [
#         "Which zone is the coolest on campus?",
#         "What are the hottest zones?",
#         "How can we cool the parking lot?",
#         "Best time for outdoor activities?",
#         "UV protection recommendations?",
#     ]
#     for i, sample in enumerate(samples):
#         if st.button(sample, key=f"sample_{i}"):
#             st.session_state.qa_query = sample
# 
# # =========================================================
# # PAGE 3: ZONE DETAILS
# # =========================================================
# elif page == "ðŸŒ¡ï¸ Zone Details":
#     st.markdown("## ðŸ”¬ Detailed Zone Analysis")
#     try:
#         zones_resp = api_get("/api/v1/zones")
#         zones = zones_resp.get("zones", [])
#         if not zones:
#             st.info("No zones available")
#         else:
#             zone_names = {z.get("zone_name", f"Zone-{i}"): z.get("zone_id") for i, z in enumerate(zones)}
#             selected_zone_name = st.selectbox("Select Zone:", list(zone_names.keys()))
#             selected_zone_id = zone_names.get(selected_zone_name)
# 
#             detail = api_get(f"/api/v1/zone/{selected_zone_id}")
# 
#             col1, col2, col3, col4 = st.columns(4)
#             col1.metric("Temperature", f"{detail.get('temperature', 0)}Â°C")
#             col2.metric("UV Index", f"{detail.get('uv_index', 0)}")
#             col3.metric("Status", detail.get("status", "N/A"))
#             coords = detail.get("coordinates", {"lat": 0.0, "lon": 0.0})
#             col4.metric("Latitude", f"{coords.get('lat', 0.0):.4f}")
# 
#             st.markdown("---")
#             st.markdown("### ðŸ›¡ï¸ Safety Recommendations")
#             is_hot = bool(detail.get("is_hotspot", False))
#             if is_hot:
#                 recommendations = [
#                     "ðŸ”´ HIGH RISK - Avoid direct sun",
#                     "Use SPF 50+ sunscreen",
#                     "Hydrate every 15 minutes",
#                     "Seek shade immediately",
#                     "Watch for heat exhaustion symptoms",
#                 ]
#             else:
#                 recommendations = [
#                     "ðŸŸ¢ SAFE - Standard precautions sufficient",
#                     "Use SPF 30+ sunscreen",
#                     "Stay hydrated",
#                     "Wear protective clothing",
#                 ]
# 
#             with st.expander("Safety recommendations", expanded=is_hot):
#                 for rec in recommendations:
#                     st.write(rec)
# 
#     except Exception as e:
#         st.error(f"Error: {e}")
# 
# # =========================================================
# # PAGE 4: FORECAST
# # =========================================================
# elif page == "ðŸ“ˆ Forecast":
#     st.markdown("## ðŸ“Š 7-Day Temperature Forecast")
#     try:
#         forecast_resp = api_get("/api/v1/forecast")
#         df_forecast = pd.DataFrame(forecast_resp.get("forecast", []))
#         if not df_forecast.empty:
#             # Ensure proper types
#             try:
#                 df_forecast["date"] = pd.to_datetime(df_forecast["date"])
#             except Exception:
#                 pass
# 
#             t1, t2 = st.tabs(["Chart", "Table"])
#             with t1:
#                 fig = go.Figure()
#                 if "max_temp" in df_forecast:
#                     fig.add_trace(go.Scatter(x=df_forecast["date"], y=df_forecast["max_temp"], name="Max", mode="lines+markers"))
#                 if "min_temp" in df_forecast:
#                     fig.add_trace(go.Scatter(x=df_forecast["date"], y=df_forecast["min_temp"], name="Min", mode="lines+markers"))
#                 if "avg_temp" in df_forecast:
#                     fig.add_trace(go.Scatter(x=df_forecast["date"], y=df_forecast["avg_temp"], name="Average", mode="lines+markers"))
#                 fig.update_layout(title="Campus Temperature Forecast", xaxis_title="Date", yaxis_title="Temperature (Â°C)")
#                 fig.add_hline(y=0, line_dash="dash", annotation_text="Baseline")
#                 st.plotly_chart(fig, use_container_width=True)
# 
#             with t2:
#                 st.dataframe(df_forecast, use_container_width=True)
#         else:
#             st.info("No forecast data available")
#     except Exception as e:
#         st.error(f"Error: {e}")
# 
# # =========================================================
# # PAGE 5: ROI
# # =========================================================
# elif page == "ðŸ’° ROI":
#     st.markdown("## ðŸ’° Cooling Intervention ROI Analysis")
# 
#     interventions = ["shade_trees", "cool_roof", "mist_cooling", "green_roof"]
#     names = {
#         "shade_trees": "ðŸŒ³ Plant Shade Trees",
#         "cool_roof": "ðŸ  Cool Roof Paint",
#         "mist_cooling": "ðŸ’¨ Mist Cooling System",
#         "green_roof": "ðŸŒ± Green Roof System"
#     }
#     selected = st.selectbox("Select Intervention:", interventions, format_func=lambda x: names[x])
# 
#     try:
#         roi = api_get(f"/api/v1/roi/{selected}")
# 
#         col1, col2, col3, col4 = st.columns(4)
#         col1.metric("Initial Cost", roi.get("initial_cost", "â‚¹0"))
#         col2.metric("Annual Savings", roi.get("annual_savings", "â‚¹0"))
#         col3.metric("Payback Period", roi.get("payback_period", "N/A"))
#         col4.metric("Cooling Effect", roi.get("cooling_effect", "N/A"))
# 
#         st.markdown("---")
#         st.markdown("### ðŸ“ˆ 5-Year Projection")
# 
#         cost = parse_lakh(roi.get("initial_cost", "0"))
#         savings = parse_lakh(roi.get("annual_savings", "0"))
#         years = list(range(1, 6))
#         cumulative = [savings * y - cost for y in years]
# 
#         fig = px.line(x=years, y=cumulative, markers=True, title="Cumulative Savings Over 5 Years")
#         fig.add_hline(y=0, line_dash="dash", annotation_text="Break-even")
#         fig.update_xaxes(title="Year")
#         fig.update_yaxes(title="â‚¹ Lakhs (net)")
#         st.plotly_chart(fig, use_container_width=True)
# 
#     except Exception as e:
#         st.error(f"Error: {e}")
# 
# # =========================================================
# # PAGE 6: ANALYTICS
# # =========================================================
# elif page == "ðŸ”¬ Analytics":
#     st.markdown("## ðŸ“Š Advanced Analytics & Insights")
#     try:
#         insights = api_get("/api/v1/insights")
# 
#         col1, col2, col3, col4 = st.columns(4)
#         col1.metric("Temp Variance", f"{insights.get('temperature_variance', 0)}Â°CÂ²")
#         col2.metric("Std Deviation", f"{insights.get('std_deviation', 0):.1f}Â°C" if isinstance(insights.get('std_deviation', 0), (int, float)) else str(insights.get('std_deviation', 'N/A')))
#         col3.metric("Hotspot %", f"{insights.get('hotspot_percentage', 0):.1f}%"
#                   if isinstance(insights.get('hotspot_percentage', 0), (int, float)) else str(insights.get('hotspot_percentage', 'N/A')))
#         col4.metric("Safe Zones %", f"{insights.get('safe_zones_percentage', 0):.1f}%"
#                   if isinstance(insights.get('safe_zones_percentage', 0), (int, float)) else str(insights.get('safe_zones_percentage', 'N/A')))
# 
#         st.markdown("---")
#         st.markdown("### ðŸ¤– AI Recommendations")
#         for rec in insights.get("recommendations", []):
#             st.write(rec)
# 
#         st.markdown("---")
#         st.markdown("### ðŸ“‹ Analysis Summary")
#         try:
#             summary_text = f"""
# **Campus Thermal Status:**
# - Average temperature variance of {insights.get('temperature_variance', 'N/A')}Â°CÂ² indicates significant hot spots
# - {insights.get('hotspot_percentage', 0):.1f}% of zones classified as high-risk hotspots
# - {insights.get('safe_zones_percentage', 0):.1f}% of zones maintain safe thermal conditions
# 
# **Recommended Actions:**
# 1. Install cooling interventions in hotspot zones
# 2. Monitor daily temperature fluctuations
# 3. Implement shade structures in high-risk areas
# 4. Educate campus community about heat safety
# """
#         except Exception:
#             summary_text = "Summary unavailable due to missing fields."
#         st.info(summary_text)
#     except Exception as e:
#         st.error(f"Error: {e}")
# 
# # ------------------------ Footer ------------------------
# st.markdown("---")
# st.markdown("### ðŸ“± Running On:")
# st.code("Google Colab (FastAPI Backend + Streamlit Frontend)")
# st.caption("Chandigarh University Thermal Digital Twin | Championship Edition | 2025")

import subprocess
import threading
import time

print("Starting backend...")

def run_backend():
    subprocess.run(["python", "/content/app_backend.py"])

backend_thread = threading.Thread(target=run_backend, daemon=True)
backend_thread.start()

time.sleep(5)  # Wait for backend to start

print("âœ… Backend started on http://localhost:8000")
print("âœ… Ready for Streamlit!")

!streamlit run /content/app_frontend.py \
  --server.port=8501 \
  --server.address=0.0.0.0 \
  --server.headless=true \
  --logger.level=error

from pyngrok import ngrok
import time

# Get Streamlit URL
time.sleep(3)
public_url = ngrok.connect(8501)
print(f"\nâœ… STREAMLIT URL: {public_url}")
print("\nShare this URL with judges!")

# Add to app_frontend.py under page == "ðŸ“Š Dashboard"

import folium
from streamlit_folium import st_folium

st.markdown("### ðŸ—ºï¸ Campus Thermal Heatmap")

# Create map centered on Chandigarh
m = folium.Map(location=[30.9010, 75.8573], zoom_start=15)

# Add zone markers with colors
zone_coords = {
    "main_parking": [30.9020, 75.8580],
    "academic_blocka": [30.9015, 75.8570],
    "library": [30.9000, 75.8600],
    "green_quad": [30.8990, 75.8585],
    "sports_complex": [30.9030, 75.8550],
}

for zone_id, zone_data in zones.items():
    if zone_id in zone_coords:
        temp = zone_data['temperature']
        color = 'red' if zone_data['is_hotspot'] else 'orange' if temp > 36 else 'green'

        folium.CircleMarker(
            location=zone_coords[zone_id],
            radius=10,
            popup=f"{zone_data['zone_name']}: {temp}Â°C",
            color=color,
            fill=True
        ).add_to(m)

st_folium(m, width=700, height=500)

# Add to app_frontend.py

import pandas as pd
import plotly.graph_objects as go

st.markdown("### ðŸ“ˆ 7-Day Temperature Forecast")

# Generate forecast data
from datetime import datetime, timedelta

dates = [(datetime.now() + timedelta(days=i)).strftime('%b %d') for i in range(7)]
forecast_data = {
    'Date': dates,
    'Max Temp': [42, 43, 41, 40, 39, 38, 37],
    'Min Temp': [28, 29, 28, 27, 26, 25, 24],
    'Avg Temp': [35, 36, 34.5, 33.5, 32.5, 31.5, 30.5]
}

df_forecast = pd.DataFrame(forecast_data)

fig = go.Figure()
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Max Temp'], name='Max'))
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Min Temp'], name='Min'))
fig.add_trace(go.Scatter(x=df_forecast['Date'], y=df_forecast['Avg Temp'], name='Average'))

st.plotly_chart(fig, use_container_width=True)

# Add new page to app_frontend.py

elif page == "ðŸ’° ROI Calculator":
    st.markdown("## ðŸ’° Cooling Intervention ROI")

    intervention = st.selectbox(
        "Select Intervention:",
        ["Shade Trees", "Cool Roof Paint", "Mist Cooling", "Green Roof"]
    )

    roi_data = {
        "Shade Trees": {"cost": 2, "savings": 0.25, "payback": 8},
        "Cool Roof Paint": {"cost": 3, "savings": 0.40, "payback": 7.5},
        "Mist Cooling": {"cost": 4, "savings": 0.15, "payback": 26},
        "Green Roof": {"cost": 10, "savings": 0.50, "payback": 20},
    }

    data = roi_data[intervention]

    col1, col2, col3 = st.columns(3)
    col1.metric("Initial Cost", f"â‚¹{data['cost']}L")
    col2.metric("Annual Savings", f"â‚¹{data['savings']}L")
    col3.metric("Payback Period", f"{data['payback']} years")

    # 5-year projection
    years = list(range(1, 6))
    savings = [data['savings'] * y - data['cost'] for y in years]

    fig = px.line(x=years, y=savings, markers=True, title="5-Year ROI Projection")
    st.plotly_chart(fig, use_container_width=True)

# Add new endpoint to app_backend.py

@app.get("/api/v1/insights")
def get_ml_insights():
    """
    Advanced ML insights about campus thermal patterns
    """
    temps = [z['temp'] for z in zones_data.values()]

    # Calculate statistics
    variance = float(np.var(temps))
    std_dev = float(np.std(temps))

    # Trend analysis
    hotspot_zones = [z for z in zones_data.values() if z['temp'] > 40]
    safe_zones = [z for z in zones_data.values() if z['temp'] < 35]

    return {
        "temperature_variance": round(variance, 2),
        "std_deviation": round(std_dev, 2),
        "hotspot_percentage": round(len(hotspot_zones) / len(zones_data) * 100, 1),
        "safe_zones_percentage": round(len(safe_zones) / len(zones_data) * 100, 1),
        "recommendations": [
            f"Prioritize cooling in {len(hotspot_zones)} high-risk zones",
            f"Monitor {len(zones_data) - len(hotspot_zones) - len(safe_zones)} moderate zones",
            f"Maintain {len(safe_zones)} safe zones"
        ]
    }

elif page == "ðŸ“Š Analytics":
    st.markdown("## ðŸ“ˆ Advanced Analytics")

    insights = requests.get(f"{API_URL}/api/v1/insights").json()

    col1, col2, col3 = st.columns(3)
    col1.metric("Temp Variance", f"{insights['temperature_variance']}Â°CÂ²")
    col2.metric("Hotspot %", f"{insights['hotspot_percentage']}%")
    col3.metric("Safe Zones %", f"{insights['safe_zones_percentage']}%")

    st.markdown("### AI Recommendations:")
    for rec in insights['recommendations']:
        st.write(f"ðŸ¤– {rec}")

elif page == "âš–ï¸ Compare Zones":
    st.markdown("## âš–ï¸ Zone Comparison")

    response = requests.get(f"{API_URL}/api/v1/zones").json()
    zones = response['zones']
    zone_names = [z['zone_name'] for z in zones]

    col1, col2 = st.columns(2)

    with col1:
        zone1 = st.selectbox("Zone 1:", zone_names, key="z1")

    with col2:
        zone2 = st.selectbox("Zone 2:", zone_names, key="z2")

    z1_data = next(z for z in zones if z['zone_name'] == zone1)
    z2_data = next(z for z in zones if z['zone_name'] == zone2)

    comparison_df = pd.DataFrame({
        'Metric': ['Temperature', 'UV Index', 'Status'],
        zone1: [f"{z1_data['temperature']}Â°C", z1_data['uv_index'],
                'ðŸ”´ Hotspot' if z1_data['is_hotspot'] else 'ðŸŸ¢ Safe'],
        zone2: [f"{z2_data['temperature']}Â°C", z2_data['uv_index'],
                'ðŸ”´ Hotspot' if z2_data['is_hotspot'] else 'ðŸŸ¢ Safe']
    })

    st.dataframe(comparison_df)

# Add custom CSS for responsiveness
st.markdown("""
<style>
    .metric {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
    }

    .stButton > button {
        width: 100%;
        height: 45px;
        font-size: 16px;
    }

    @media (max-width: 768px) {
        .stMetric {
            min-width: 100%;
        }
    }
</style>
""", unsafe_allow_html=True)
